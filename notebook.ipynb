{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any\n",
    "from torch import Tensor\n",
    "from torch.nn import Module\n",
    "from torch.optim import Optimizer\n",
    "from torchsystem.aggregate import Aggregate, Loader\n",
    "from torchsystem.callbacks import Callback\n",
    "\n",
    "class Classifier(Aggregate):\n",
    "    def __init__(self, id: Any, model: Module, criterion: Module, optimizer: Optimizer):\n",
    "        super().__init__(id)        \n",
    "        self.model = model\n",
    "        self.criterion = criterion\n",
    "        self.optimizer = optimizer\n",
    "\n",
    "    def forward(self, input: Tensor) -> Tensor:\n",
    "        return self.model(input)\n",
    "\n",
    "    def loss(self, output: Tensor, target: Tensor) -> Tensor:\n",
    "        return self.criterion(output, target)\n",
    "\n",
    "    def fit(self, data: Loader, callback: Callback):\n",
    "        for batch, (input, target) in enumerate(data, start=1):\n",
    "            output = self(input)\n",
    "            loss = self.loss(output, target)\n",
    "            self.optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "            callback(batch, loss.item(), output, target, input)\n",
    "\n",
    "    def evaluate(self, data: Loader, callback: Callback):\n",
    "        for batch, (input, target) in enumerate(data, start=1):\n",
    "            output = self(input)\n",
    "            loss = self.loss(output, target)\n",
    "            callback(batch, loss.item(), output, target, input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import Module\n",
    "from torch.nn import ReLU, Linear\n",
    "from torch.nn import Dropout\n",
    "\n",
    "class MLP(Module):\n",
    "    def __init__(self, input_size: int, hidden_size: int, output_size: int, p: float):\n",
    "        super().__init__()\n",
    "        self.input_layer = Linear(input_size, hidden_size)\n",
    "        self.activation = ReLU()\n",
    "        self.dropout = Dropout(p)\n",
    "        self.output_layer = Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, sequence: Tensor) -> Tensor:\n",
    "        sequence = self.input_layer(sequence)\n",
    "        sequence = self.activation(sequence)\n",
    "        sequence = self.dropout(sequence)\n",
    "        sequence = self.output_layer(sequence)\n",
    "        return sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets.mnist import MNIST\n",
    "from torchvision.transforms import Compose, ToTensor, Normalize\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class Digits(Dataset):\n",
    "    def __init__(self, train: bool, normalize: bool):\n",
    "        transform = Compose([ToTensor()]) if not normalize else Compose([ToTensor(), Normalize((0.5,), (0.5,))])\n",
    "        self.dataset = MNIST(root='data/datasets', train=train, download=True, transform=transform)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, index: int):\n",
    "        return self.dataset[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.optim import Adam\n",
    "from torchsystem.compiler import Compiler\n",
    "from torchsystem.callbacks import Callbacks, Loss, Accuracy\n",
    "from torchsystem.loaders import Loaders\n",
    "from torchsystem.registry import Models, Criterions, Optimizers, Datasets\n",
    "\n",
    "Models.register(MLP)\n",
    "Criterions.register(CrossEntropyLoss)\n",
    "Optimizers.register(Adam)\n",
    "Datasets.register(Digits)\n",
    "\n",
    "model = MLP(784, 128, 10, p=0.2)\n",
    "criterion = CrossEntropyLoss()\n",
    "optimizer = Adam(model.parameters(), lr=0.001)\n",
    "loaders = Loaders()\n",
    "loaders.add('train', Digits(train=True, normalize=True), batch_size=32, shuffle=True)\n",
    "loaders.add('test', Digits(train=False, normalize=True), batch_size=32, shuffle=False)\n",
    "\n",
    "callback = Callbacks([Loss(), Accuracy()])\n",
    "compiler = Compiler(Classifier)\n",
    "aggregate = compiler.compile('0', model, criterion, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metadata(type='dataset', hash='c728058dbf80e17ebf0aba2bc09e0dc7', name='Digits', arguments={'train': True, 'normalize': True})\n",
      "Metadata(type='dataset', hash='c728058dbf80e17ebf0aba2bc09e0dc7', name='Digits', arguments={'train': False, 'normalize': True})\n"
     ]
    }
   ],
   "source": [
    "from mlregistry import get_metadata\n",
    "for phase, loader in loaders:\n",
    "    print(get_metadata(loader.dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsystem.weights import Weights\n",
    "\n",
    "weights = Weights(directory='data/weights')\n",
    "weights.store(model, 'model', '123')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metadata(type='optimizer', hash='55b114a06ec82cec384573d24663dafe', name='Adam', arguments={'lr': 0.001})\n"
     ]
    }
   ],
   "source": [
    "print(get_metadata(aggregate.optimizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
