{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ignore this. For making the example's imports work in this folder.\n",
    "import sys, os\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..', '..')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import Tensor\n",
    "from torch import inference_mode\n",
    "from torch.nn import Module\n",
    "from torch.optim import Optimizer\n",
    "from torchsystem import Loader\n",
    "from torchsystem import Aggregate\n",
    "from typing import Callable\n",
    "\n",
    "class Classifier(Aggregate):\n",
    "    def __init__(self, model: Module, criterion: Module, optimizer: Optimizer):\n",
    "        super().__init__()\n",
    "        self.epoch = 0\n",
    "        self.model = model\n",
    "        self.criterion = criterion\n",
    "        self.optimizer = optimizer\n",
    "\n",
    "    def forward(self, input: Tensor) -> Tensor:\n",
    "        return self.model(input)\n",
    "    \n",
    "    def loss(self, output: Tensor, target: Tensor) -> Tensor:\n",
    "        return self.criterion(output, target)\n",
    "\n",
    "    def fit(self, input: Tensor, target: Tensor) -> tuple[Tensor, float]:\n",
    "        self.optimizer.zero_grad()\n",
    "        output = self(input)\n",
    "        loss = self.loss(output, target)\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "        return output, loss.item()\n",
    "\n",
    "    def evaluate(self, input: Tensor, target: Tensor) -> tuple[Tensor, float]: \n",
    "        output = self(input)\n",
    "        loss = self.loss(output, target)\n",
    "        return output, loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(aggregate: Aggregate, loader: Loader, callback: Callable, device: str):\n",
    "    aggregate.phase = 'train'\n",
    "    for batch, (input, target) in enumerate(loader, start=1):\n",
    "        input, target = input.to(device), target.to(device)\n",
    "        output, loss = aggregate.fit(input, target)\n",
    "        callback(batch, output, target, loss)\n",
    "\n",
    "def evaluate(aggregate: Aggregate, loader: Loader, callback: Callable, device: str):\n",
    "    aggregate.phase = 'evaluation'\n",
    "    with inference_mode():\n",
    "        for batch, (input, target) in enumerate(loader, start=1):\n",
    "            input, target = input.to(device), target.to(device)\n",
    "            output, loss = aggregate.evaluate(input, target)\n",
    "            callback(batch, output, target, loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsystem.metrics import Callback\n",
    "from torchsystem.metrics.average import Loss, Accuracy\n",
    "\n",
    "callback = Callback(Loss(), Accuracy())\n",
    "\n",
    "@callback.handler\n",
    "def handle_results(batch: int, output: Tensor, target: Tensor, loss: float):\n",
    "    callback.metrics(loss=loss, predictions=output.argmax(dim=1), target=target)\n",
    "    if batch % 100 == 0:\n",
    "        print(f'Batch {batch}: average loss {callback.metrics['loss']:.2f}, average accuracy: {100*callback.metrics['accuracy']:.4f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import cuda\n",
    "from torchsystem import Compiler\n",
    "from torchsystem import Depends\n",
    "\n",
    "compiler = Compiler()\n",
    "\n",
    "def get_device():\n",
    "    return 'cuda' if cuda.is_available() else 'cpu'\n",
    "\n",
    "@compiler.step\n",
    "def build_classifier(model, criterion, optimizer, device = Depends(get_device)) -> Classifier:\n",
    "    classifier = Classifier(model, criterion, optimizer).to(device)\n",
    "    return compiler.compile(classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 100: average loss 1.16, average accuracy: 56.6875%\n",
      "Batch 200: average loss 0.95, average accuracy: 64.5312%\n",
      "Batch 300: average loss 0.86, average accuracy: 67.5833%\n",
      "Batch 400: average loss 0.80, average accuracy: 69.9844%\n",
      "Batch 500: average loss 0.77, average accuracy: 71.2562%\n",
      "Batch 600: average loss 0.74, average accuracy: 72.6667%\n",
      "Batch 700: average loss 0.72, average accuracy: 73.5179%\n",
      "Batch 800: average loss 0.70, average accuracy: 74.2539%\n",
      "Batch 900: average loss 0.68, average accuracy: 74.7257%\n",
      "Batch 1000: average loss 0.67, average accuracy: 75.3406%\n",
      "Batch 1100: average loss 0.66, average accuracy: 75.8267%\n",
      "Batch 1200: average loss 0.65, average accuracy: 76.2734%\n",
      "Batch 1300: average loss 0.64, average accuracy: 76.5168%\n",
      "Batch 1400: average loss 0.63, average accuracy: 76.7812%\n",
      "Batch 1500: average loss 0.63, average accuracy: 77.1042%\n",
      "Batch 1600: average loss 0.62, average accuracy: 77.3887%\n",
      "Batch 1700: average loss 0.61, average accuracy: 77.5699%\n",
      "Batch 1800: average loss 0.61, average accuracy: 77.7708%\n",
      "Epoch 1 train completed\n",
      "Average loss: 0.60, Average accuracy: 77.9533%\n",
      "Batch 100: average loss 0.43, average accuracy: 84.6250%\n",
      "Batch 200: average loss 0.45, average accuracy: 84.0469%\n",
      "Batch 300: average loss 0.45, average accuracy: 83.7396%\n",
      "Epoch 1 evaluation completed\n",
      "Average loss: 0.45, Average accuracy: 83.8059%\n",
      "Batch 100: average loss 0.53, average accuracy: 81.8750%\n",
      "Batch 200: average loss 0.51, average accuracy: 81.8750%\n",
      "Batch 300: average loss 0.51, average accuracy: 81.6875%\n",
      "Batch 400: average loss 0.51, average accuracy: 81.8047%\n",
      "Batch 500: average loss 0.50, average accuracy: 81.9938%\n",
      "Batch 600: average loss 0.50, average accuracy: 81.9323%\n",
      "Batch 700: average loss 0.50, average accuracy: 82.0000%\n",
      "Batch 800: average loss 0.50, average accuracy: 82.0508%\n",
      "Batch 900: average loss 0.50, average accuracy: 82.1285%\n",
      "Batch 1000: average loss 0.50, average accuracy: 82.2594%\n",
      "Batch 1100: average loss 0.50, average accuracy: 82.2500%\n",
      "Batch 1200: average loss 0.49, average accuracy: 82.3906%\n",
      "Batch 1300: average loss 0.49, average accuracy: 82.3221%\n",
      "Batch 1400: average loss 0.49, average accuracy: 82.3259%\n",
      "Batch 1500: average loss 0.49, average accuracy: 82.3417%\n",
      "Batch 1600: average loss 0.49, average accuracy: 82.3594%\n",
      "Batch 1700: average loss 0.49, average accuracy: 82.4118%\n",
      "Batch 1800: average loss 0.49, average accuracy: 82.5052%\n",
      "Epoch 2 train completed\n",
      "Average loss: 0.49, Average accuracy: 82.5467%\n",
      "Batch 100: average loss 0.41, average accuracy: 85.5625%\n",
      "Batch 200: average loss 0.42, average accuracy: 84.8906%\n",
      "Batch 300: average loss 0.42, average accuracy: 84.6667%\n",
      "Epoch 2 evaluation completed\n",
      "Average loss: 0.42, Average accuracy: 84.7544%\n",
      "Batch 100: average loss 0.47, average accuracy: 82.4688%\n",
      "Batch 200: average loss 0.46, average accuracy: 83.2344%\n",
      "Batch 300: average loss 0.46, average accuracy: 83.0625%\n",
      "Batch 400: average loss 0.46, average accuracy: 83.0000%\n",
      "Batch 500: average loss 0.47, average accuracy: 82.9812%\n",
      "Batch 600: average loss 0.46, average accuracy: 83.2865%\n",
      "Batch 700: average loss 0.46, average accuracy: 83.2723%\n",
      "Batch 800: average loss 0.47, average accuracy: 83.1406%\n",
      "Batch 900: average loss 0.47, average accuracy: 83.2153%\n",
      "Batch 1000: average loss 0.47, average accuracy: 83.1438%\n",
      "Batch 1100: average loss 0.47, average accuracy: 83.2188%\n",
      "Batch 1200: average loss 0.47, average accuracy: 83.2161%\n",
      "Batch 1300: average loss 0.47, average accuracy: 83.2212%\n",
      "Batch 1400: average loss 0.47, average accuracy: 83.2701%\n",
      "Batch 1500: average loss 0.47, average accuracy: 83.2750%\n",
      "Batch 1600: average loss 0.47, average accuracy: 83.1426%\n",
      "Batch 1700: average loss 0.46, average accuracy: 83.2390%\n",
      "Batch 1800: average loss 0.46, average accuracy: 83.3628%\n",
      "Epoch 3 train completed\n",
      "Average loss: 0.46, Average accuracy: 83.3500%\n",
      "Batch 100: average loss 0.38, average accuracy: 85.3125%\n",
      "Batch 200: average loss 0.40, average accuracy: 84.7188%\n",
      "Batch 300: average loss 0.40, average accuracy: 84.6979%\n",
      "Epoch 3 evaluation completed\n",
      "Average loss: 0.40, Average accuracy: 84.8442%\n",
      "Batch 100: average loss 0.42, average accuracy: 83.8437%\n",
      "Batch 200: average loss 0.43, average accuracy: 83.6562%\n",
      "Batch 300: average loss 0.44, average accuracy: 83.7292%\n",
      "Batch 400: average loss 0.45, average accuracy: 83.7656%\n",
      "Batch 500: average loss 0.45, average accuracy: 83.8500%\n",
      "Batch 600: average loss 0.45, average accuracy: 83.7917%\n",
      "Batch 700: average loss 0.45, average accuracy: 83.8839%\n",
      "Batch 800: average loss 0.46, average accuracy: 83.7617%\n",
      "Batch 900: average loss 0.45, average accuracy: 83.8819%\n",
      "Batch 1000: average loss 0.45, average accuracy: 83.9062%\n",
      "Batch 1100: average loss 0.45, average accuracy: 83.9574%\n",
      "Batch 1200: average loss 0.45, average accuracy: 84.0417%\n",
      "Batch 1300: average loss 0.45, average accuracy: 84.0625%\n",
      "Batch 1400: average loss 0.45, average accuracy: 84.0290%\n",
      "Batch 1500: average loss 0.45, average accuracy: 84.0271%\n",
      "Batch 1600: average loss 0.45, average accuracy: 84.0312%\n",
      "Batch 1700: average loss 0.45, average accuracy: 84.0294%\n",
      "Batch 1800: average loss 0.45, average accuracy: 84.0434%\n",
      "Epoch 4 train completed\n",
      "Average loss: 0.45, Average accuracy: 84.0717%\n",
      "Batch 100: average loss 0.38, average accuracy: 85.7812%\n",
      "Batch 200: average loss 0.41, average accuracy: 85.1094%\n",
      "Batch 300: average loss 0.41, average accuracy: 85.2917%\n",
      "Epoch 4 evaluation completed\n",
      "Average loss: 0.40, Average accuracy: 85.4832%\n",
      "Batch 100: average loss 0.41, average accuracy: 85.5312%\n",
      "Batch 200: average loss 0.43, average accuracy: 85.2031%\n",
      "Batch 300: average loss 0.44, average accuracy: 84.4375%\n",
      "Batch 400: average loss 0.44, average accuracy: 84.2266%\n",
      "Batch 500: average loss 0.44, average accuracy: 84.1750%\n",
      "Batch 600: average loss 0.44, average accuracy: 84.2083%\n",
      "Batch 700: average loss 0.44, average accuracy: 84.3527%\n",
      "Batch 800: average loss 0.44, average accuracy: 84.2930%\n",
      "Batch 900: average loss 0.44, average accuracy: 84.3646%\n",
      "Batch 1000: average loss 0.44, average accuracy: 84.4969%\n",
      "Batch 1100: average loss 0.44, average accuracy: 84.4574%\n",
      "Batch 1200: average loss 0.44, average accuracy: 84.4010%\n",
      "Batch 1300: average loss 0.44, average accuracy: 84.3702%\n",
      "Batch 1400: average loss 0.44, average accuracy: 84.4018%\n",
      "Batch 1500: average loss 0.44, average accuracy: 84.4062%\n",
      "Batch 1600: average loss 0.44, average accuracy: 84.4375%\n",
      "Batch 1700: average loss 0.44, average accuracy: 84.4614%\n",
      "Batch 1800: average loss 0.44, average accuracy: 84.4479%\n",
      "Epoch 5 train completed\n",
      "Average loss: 0.44, Average accuracy: 84.5000%\n",
      "Batch 100: average loss 0.39, average accuracy: 85.0938%\n",
      "Batch 200: average loss 0.41, average accuracy: 84.7344%\n",
      "Batch 300: average loss 0.40, average accuracy: 84.8229%\n",
      "Epoch 5 evaluation completed\n",
      "Average loss: 0.40, Average accuracy: 84.9241%\n"
     ]
    }
   ],
   "source": [
    "from examples.basic.model import MLP\n",
    "from examples.basic.dataset import Fashion\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "model = MLP(784, 256, 10, 0.5, 'relu')\n",
    "criterion = CrossEntropyLoss()\n",
    "optimizer = Adam(model.parameters(), lr=0.001)\n",
    "loaders = [\n",
    "    ('train', DataLoader(Fashion(train=True), batch_size=32, shuffle=True)),\n",
    "    ('evaluation', DataLoader(Fashion(train=False), batch_size=32, shuffle=False))\n",
    "]\n",
    "aggregate = compiler(model, criterion, optimizer)\n",
    "\n",
    "for epoch in range(5):\n",
    "    for phase, loader in loaders:\n",
    "        if phase == 'train':\n",
    "            train(aggregate, loader, callback, get_device())\n",
    "        else:\n",
    "            evaluate(aggregate, loader, callback, get_device())\n",
    "        print(f'Epoch {epoch+1} {phase} completed')\n",
    "        print(f'Average loss: {callback.metrics[\"loss\"]:.2f}, Average accuracy: {100*callback.metrics[\"accuracy\"]:.4f}%')\n",
    "        callback.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
